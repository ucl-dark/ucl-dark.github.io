



<!DOCTYPE html>
<html lang="en">
  <head>
    
    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <link rel="stylesheet" href="static/css/main.css" type="text/css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />
    <link rel="icon" href="static/images/logo.png">

    <!-- External Javascript libs  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
    <script src="https://kit.fontawesome.com/c59ce62110.js" crossorigin="anonymous"></script>

    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>


    <!-- Library libs -->
    <script src="static/js/typeahead.bundle.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
      href="static/css/Lato.css"
      rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link
      href="static/css/Cuprum.css"
      rel="stylesheet"
    />

    <title>UCL DARK Lab: Speakers</title>
    
  </head>

  <body>
    <!-- NAV -->
    
    <nav
      class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
      id="main-nav"
    >
        <div class="container">
        <!--
        <a class="navbar-brand" href="index.html">
          <img
             class="logo" src="static/images/logo.png"
             height="auto"
             width="120px"
          />
        </a>
        -->
        
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div
          class="collapse navbar-collapse text-right flex-grow-1"
          id="navbarNav"
        >
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html">Publications</a>
            </li>
            
            <li class="nav-item active">
              <a class="nav-link" href="speakers.html">Speakers</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->
     

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        
<div class="tab-content py-3 px-3 px-sm-0" id="nav-tabContent">
  <div id="day">
    <!-- Workshops -->
    <div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Speakers</h2>
  </div>
</div>
    <div class="speakers">
      <div class="cards row">
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_7.html">
          <h3 class="card-title main-title">
            On Question Answering on Images and Databases
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Dzmitry Bahdanau / McGill University
        </div>
        <div class="card-subtitle text-muted">
          Mar 15, 2021
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          The AI's ability to answer questions that are grounded in context is interesting from both academic and practical perspectives. In this talk, I will present two projects that study question answering (QA) in visual and symbolic database context respectively. In the first project my collaborators and I show that a neuro-symbolic visual QA system can learn variable bindings from the top-down QA training signal only. The system successfully learns both conventional bindings (e.g. objects) and less trivial ones (e.g. groups). In our second project my colleagues at Element AI and I explore text2sql systems for answering questions about databases. We perform extensive ablation testing to understand what is really necessary for such systems to achieve best performance. I will end the talk with a quick preview of our on-going few-shot text2sql research efforts.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_6.html">
          <h3 class="card-title main-title">
            Learning to Cooperate, Communicate and Coordinate
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Jakob Foerster / Facebook AI Research
        </div>
        <div class="card-subtitle text-muted">
          Mar 08, 2021
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          In recent years we have seen rapid progress on a number of zero-sum benchmark problems in artificial intelligence, e.g. Go, Poker and Dota. In contrast to these competitive settings, success in the real world typically requires humans, and will require AI agents, to cooperate, communicate and coordinate with others. Crucially, from a learning point of view, these three Cs require fundamentally novel approaches, methods and theory, which has been at the heart of my research agenda. In my talk I will cover recent progress, including how agents can learn to entice others to cooperate in settings of conflicting goals by accounting for their learning behaviour, how they can learn to communicate by reasoning over (public) beliefs and how they can learn policies that can coordinate with other agents at test time by exploiting the symmetries in the environment. I will finish the talk by outlining some of the promising directions for future work.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_5.html">
          <h3 class="card-title main-title">
            Grounded Language Learning Without Grounded Supervision
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Jacob Andreas / MIT
        </div>
        <div class="card-subtitle text-muted">
          Mar 01, 2021
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          Central to tasks like instruction following and question answering is the ability to ground linguistic understanding in perception and action. Machine learning models for these tasks typically rely on grounded supervision, e.g. actions paired with human-generated instructions or images paired with human-generated questions and answers. Indeed, several recent papers have argued that general-purpose language understanding (even in text-only tasks like machine reading and text generation) is impossible without grounding. In this talk, I'll present two studies on improving grounded language learning without grounded supervision. First, I'll describe an approach for using multi-agent interaction to fine-tune models for instruction following and instruction generation---without additional human-generated text. Next, I'll describe some very recent work suggesting that language models trained on text alone---without any grounding---are capable of building implicit world models and simulating interactions between entities described in discourse.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_4.html">
          <h3 class="card-title main-title">
            Increasing generality in reinforcement learning through procedural content generation (or have fun trying)
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Julian Togelius / New York University
        </div>
        <div class="card-subtitle text-muted">
          Jan 18, 2021
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          Julian Togelius will be giving a talk with the title: "Increasing generality in reinforcement learning through procedural content generation (or have fun trying)", exploring how to make reinforcement learning algorithms overfit to their training environments less, and the use of procedural content generation in reinforcement learning.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_3.html">
          <h3 class="card-title main-title">
            Intuitive Reasoning as (Un)supervised Neural Generation
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Yejin Choi / University of Washington
        </div>
        <div class="card-subtitle text-muted">
          Jan 04, 2021
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          Neural language models, as they grow in scale, continue to surprise us with utterly nonsensical and counterintuitive errors despite their otherwise remarkable performances on leaderboards. In this talk, I will argue that it is time to challenge the currently dominant paradigm of task-specific supervision built on top of large-scale self-supervised neural networks. I will first highlight how we can make better lemonade out of neural language models by shifting our focus on unsupervised, inference-time algorithms. I will demonstrate how unsupervised algorithms can match or even outperform supervised approaches on hard reasoning tasks such as nonmonotonic reasoning (such as counterfactual and abductive reasoning), or complex language generation tasks that require logical constraints. Next, I will highlight the importance of melding explicit and declarative knowledge encoded in symbolic knowledge graphs with implicit and observed knowledge encoded in neural language models. I will present COMET, Commonsense Transformers that learn neural representation of commonsense reasoning from a symbolic commonsense knowledge graph, and Social Chemistry 101, a new conceptual formalism, a knowledge graph, and neural models to reason about social, moral, and ethical norms.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_2.html">
          <h3 class="card-title main-title">
            Social Reinforcement Learning
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Natasha Jaques / Google Brain
        </div>
        <div class="card-subtitle text-muted">
          Dec 21, 2020
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          Social learning helps humans and animals rapidly adapt to new circumstances, and drives the emergence of complex learned behaviors. This talk focuses on Social Reinforcement Learning, developing new RL algorithms that leverage social learning to improve single-agent learning and generalization, multi-agent coordination, and human-AI interaction. We will demonstrate how a multi-agent technique for Adversarial Environment Generation based on minimax regret can lead to the generation of a complex curriculum of training environments, which improves an agent’s zero-shot transfer to unknown, single-agent test tasks. To improve multi-agent coordination, we give agents an intrinsic motivation to increase their causal influence over the actions of other agents, and show that this leads to the emergence of communication and enhances cooperation. Finally, we propose a novel Offline RL technique for learning from intrinsic social cues during interaction with humans in an open-domain dialog setting. Together, this work argues that Social RL is a valuable approach for developing more general, sophisticated, and human-compatible AI.
        </div>
      </div>
    </div>
  </div>
  
  <div class="col-md-6 col-sm-12 p-3" style="box-sizing: border-box;">
    <div class="card" style="display: block; overflow: hidden; width: 100%;">
      <div
        class="card-header text-center"
        style="min-height: 200px; width: 100%;"
      >
        <a class="text-muted" href="speaker_1.html">
          <h3 class="card-title main-title">
            Promise, Progress, and Challenges in Open-Ended Machine Learning
          </h3>
        </a>
        <div class="card-subtitle text-muted">
          Joel Lehman / OpenAI
        </div>
        <div class="card-subtitle text-muted">
          Nov 23, 2020
        </div>
        <div class="m-3 text-left card-subtitle font-italic">
          Researchers in open-ended machine learning are inspired by natural and human processes of innovation (like biological evolution or science itself), and aim to uncover the engineering principles underlying boundlessly creative search algorithms, i.e. algorithms capable of continual production of useful and interesting innovations, The speculative promise for machine learning from such open-ended search includes automated discovery of curricula for reinforcement learning, new neural architectures, and most ambitiously, AGI itself. While its most ambitious potential is far from being realized, conceptual and algorithmic progress has been made. I will review progress in open-ended search and highlight open challenges.
        </div>
      </div>
    </div>
  </div>
  
</div>
    </div>
  </div>
</div>

      </div>
    </div>
    
    

    <!-- Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2020 UCL DARK Lab</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
  </body>
</html>